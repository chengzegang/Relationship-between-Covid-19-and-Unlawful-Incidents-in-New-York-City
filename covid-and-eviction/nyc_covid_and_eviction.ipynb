{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "educational-constitutional",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import DateType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "great-referral",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################### Initialize SparkSession #########################\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"SparkSQL\") \\\n",
    "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "american-wisconsin",
   "metadata": {},
   "source": [
    "## Import data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "parliamentary-fireplace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- indexnumberid: string (nullable = true)\n",
      " |-- court: string (nullable = true)\n",
      " |-- fileddate: string (nullable = true)\n",
      " |-- propertytype: string (nullable = true)\n",
      " |-- classification: string (nullable = true)\n",
      " |-- specialtydesignationtypes: string (nullable = true)\n",
      " |-- status: string (nullable = true)\n",
      " |-- disposeddate: string (nullable = true)\n",
      " |-- disposedreason: string (nullable = true)\n",
      " |-- firstpaper: string (nullable = true)\n",
      " |-- primaryclaimtotal: string (nullable = true)\n",
      " |-- dateofjurydemand: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- indexnumberid: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- postalcode: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- date_of_interest: timestamp (nullable = true)\n",
      " |-- CASE_COUNT: integer (nullable = true)\n",
      " |-- PROBABLE_CASE_COUNT: integer (nullable = true)\n",
      " |-- CASE_COUNT_7DAY_AVG: integer (nullable = true)\n",
      " |-- ALL_CASE_COUNT_7DAY_AVG: integer (nullable = true)\n",
      " |-- BX_CASE_COUNT: integer (nullable = true)\n",
      " |-- BX_PROBABLE_CASE_COUNT: integer (nullable = true)\n",
      " |-- BX_CASE_COUNT_7DAY_AVG: integer (nullable = true)\n",
      " |-- BX_ALL_CASE_COUNT_7DAY_AVG: integer (nullable = true)\n",
      " |-- BK_CASE_COUNT: integer (nullable = true)\n",
      " |-- BK_PROBABLE_CASE_COUNT: integer (nullable = true)\n",
      " |-- BK_CASE_COUNT_7DAY_AVG: integer (nullable = true)\n",
      " |-- BK_ALL_CASE_COUNT_7DAY_AVG: integer (nullable = true)\n",
      " |-- MN_CASE_COUNT: integer (nullable = true)\n",
      " |-- MN_PROBABLE_CASE_COUNT: integer (nullable = true)\n",
      " |-- MN_CASE_COUNT_7DAY_AVG: integer (nullable = true)\n",
      " |-- MN_ALL_CASE_COUNT_7DAY_AVG: integer (nullable = true)\n",
      " |-- QN_CASE_COUNT: integer (nullable = true)\n",
      " |-- QN_PROBABLE_CASE_COUNT: integer (nullable = true)\n",
      " |-- QN_CASE_COUNT_7DAY_AVG: integer (nullable = true)\n",
      " |-- QN_ALL_CASE_COUNT_7DAY_AVG: integer (nullable = true)\n",
      " |-- SI_CASE_COUNT: integer (nullable = true)\n",
      " |-- SI_PROBABLE_CASE_COUNT: integer (nullable = true)\n",
      " |-- SI_CASE_COUNT_7DAY_AVG: integer (nullable = true)\n",
      " |-- SI_ALL_CASE_COUNT_7DAY_AVG: integer (nullable = true)\n",
      " |-- INCOMPLETE: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- CMPLNT_NUM: integer (nullable = true)\n",
      " |-- ADDR_PCT_CD: integer (nullable = true)\n",
      " |-- BORO_NM: string (nullable = true)\n",
      " |-- CMPLNT_FR_DT: timestamp (nullable = true)\n",
      " |-- CMPLNT_FR_TM: string (nullable = true)\n",
      " |-- CMPLNT_TO_DT: string (nullable = true)\n",
      " |-- CMPLNT_TO_TM: string (nullable = true)\n",
      " |-- CRM_ATPT_CPTD_CD: string (nullable = true)\n",
      " |-- HADEVELOPT: string (nullable = true)\n",
      " |-- HOUSING_PSA: integer (nullable = true)\n",
      " |-- JURISDICTION_CODE: integer (nullable = true)\n",
      " |-- JURIS_DESC: string (nullable = true)\n",
      " |-- KY_CD: integer (nullable = true)\n",
      " |-- LAW_CAT_CD: string (nullable = true)\n",
      " |-- LOC_OF_OCCUR_DESC: string (nullable = true)\n",
      " |-- OFNS_DESC: string (nullable = true)\n",
      " |-- PARKS_NM: string (nullable = true)\n",
      " |-- PATROL_BORO: string (nullable = true)\n",
      " |-- PD_CD: integer (nullable = true)\n",
      " |-- PD_DESC: string (nullable = true)\n",
      " |-- PREM_TYP_DESC: string (nullable = true)\n",
      " |-- RPT_DT: string (nullable = true)\n",
      " |-- STATION_NAME: string (nullable = true)\n",
      " |-- SUSP_AGE_GROUP: string (nullable = true)\n",
      " |-- SUSP_RACE: string (nullable = true)\n",
      " |-- SUSP_SEX: string (nullable = true)\n",
      " |-- TRANSIT_DISTRICT: integer (nullable = true)\n",
      " |-- VIC_AGE_GROUP: string (nullable = true)\n",
      " |-- VIC_RACE: string (nullable = true)\n",
      " |-- VIC_SEX: string (nullable = true)\n",
      " |-- X_COORD_CD: integer (nullable = true)\n",
      " |-- Y_COORD_CD: integer (nullable = true)\n",
      " |-- Latitude: double (nullable = true)\n",
      " |-- Longitude: double (nullable = true)\n",
      " |-- Lat_Lon: string (nullable = true)\n",
      " |-- New Georeferenced Column: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- CMPLNT_NUM: integer (nullable = true)\n",
      " |-- ADDR_PCT_CD: integer (nullable = true)\n",
      " |-- BORO_NM: string (nullable = true)\n",
      " |-- CMPLNT_FR_DT: timestamp (nullable = true)\n",
      " |-- CMPLNT_FR_TM: string (nullable = true)\n",
      " |-- CMPLNT_TO_DT: string (nullable = true)\n",
      " |-- CMPLNT_TO_TM: string (nullable = true)\n",
      " |-- CRM_ATPT_CPTD_CD: string (nullable = true)\n",
      " |-- HADEVELOPT: string (nullable = true)\n",
      " |-- HOUSING_PSA: integer (nullable = true)\n",
      " |-- JURISDICTION_CODE: integer (nullable = true)\n",
      " |-- JURIS_DESC: string (nullable = true)\n",
      " |-- KY_CD: integer (nullable = true)\n",
      " |-- LAW_CAT_CD: string (nullable = true)\n",
      " |-- LOC_OF_OCCUR_DESC: string (nullable = true)\n",
      " |-- OFNS_DESC: string (nullable = true)\n",
      " |-- PARKS_NM: string (nullable = true)\n",
      " |-- PATROL_BORO: string (nullable = true)\n",
      " |-- PD_CD: integer (nullable = true)\n",
      " |-- PD_DESC: string (nullable = true)\n",
      " |-- PREM_TYP_DESC: string (nullable = true)\n",
      " |-- RPT_DT: string (nullable = true)\n",
      " |-- STATION_NAME: string (nullable = true)\n",
      " |-- SUSP_AGE_GROUP: string (nullable = true)\n",
      " |-- SUSP_RACE: string (nullable = true)\n",
      " |-- SUSP_SEX: string (nullable = true)\n",
      " |-- TRANSIT_DISTRICT: integer (nullable = true)\n",
      " |-- VIC_AGE_GROUP: string (nullable = true)\n",
      " |-- VIC_RACE: string (nullable = true)\n",
      " |-- VIC_SEX: string (nullable = true)\n",
      " |-- X_COORD_CD: integer (nullable = true)\n",
      " |-- Y_COORD_CD: integer (nullable = true)\n",
      " |-- Latitude: double (nullable = true)\n",
      " |-- Longitude: double (nullable = true)\n",
      " |-- Lat_Lon: string (nullable = true)\n",
      " |-- New Georeferenced Column: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "######################### Import data set  #########################\n",
    "# cases has basic information about each case. (One row for each case)\n",
    "# addresses has address of the properties that the case concerns. (Can be one or more entries for each case)\n",
    "######################### Import oca_index data set  #########################\n",
    "\n",
    "# load cases and addresses tables\n",
    "eviction_cases = spark.read.format('csv').options(\n",
    "    header='true', inferschema='true').load(\"data/eviction_cases.csv\")\n",
    "eviction_addresses = spark.read.format('csv').options(\n",
    "    header='true', inferschema='true').load(\"data/eviction_addresses.csv\")\n",
    "covid_cases = spark.read.format('csv').options(\n",
    "    header='true', inferschema='true').load(\"data/cases-by-day.csv\")\n",
    "\n",
    "\n",
    "nypd_data_2020 = spark.read.format('csv').options(\n",
    "    header='true', inferschema='true').load(\"data/NYPD_Complaint_Data_2020.csv\")\n",
    "nypd_data_2021 = spark.read.format('csv').options(\n",
    "    header='true', inferschema='true').load(\"data/NYPD_Complaint_Data_2021.csv\")\n",
    "\n",
    "covid_cases = covid_cases.withColumn(\"date_of_interest\",to_timestamp(\"date_of_interest\", \"M/dd/yyyy\"))\n",
    "nypd_data_2020 = nypd_data_2020.withColumn(\"CMPLNT_FR_DT\",to_timestamp(\"CMPLNT_FR_DT\", \"M/dd/yyyy\"))\n",
    "nypd_data_2021 = nypd_data_2021.withColumn(\"CMPLNT_FR_DT\",to_timestamp(\"CMPLNT_FR_DT\", \"M/dd/yyyy\"))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# create temp view for spark sql \n",
    "eviction_cases.createOrReplaceTempView(\"eviction_cases\")\n",
    "eviction_addresses.createOrReplaceTempView(\"eviction_addresses\")\n",
    "covid_cases.createOrReplaceTempView(\"covid_cases\")\n",
    "nypd_data_2020.createOrReplaceTempView(\"nypd_data_2020\")\n",
    "nypd_data_2021.createOrReplaceTempView(\"nypd_data_2021\")\n",
    "\n",
    "# print schema\n",
    "eviction_cases.printSchema()\n",
    "eviction_addresses.printSchema()\n",
    "covid_cases.printSchema()\n",
    "nypd_data_2020.printSchema()\n",
    "nypd_data_2021.printSchema()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alternative-chosen",
   "metadata": {},
   "source": [
    "## Total filling of eviction in NYC after NYC lockdown (03/20/2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "amazing-gateway",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|   47949|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "######################### Total filling of eviction in NYC after NYC lockdown (03/20/2020) #########################\n",
    "\n",
    "# These classifications are consider eviction fillings: Holdover, Non-Payment\n",
    "\n",
    "# These court are in the NYC: Bronx County Civil Court, Kings County Civil Court, New York County Civil Court, Queens County Civil Court, \n",
    "# Richmond County Civil Court, Redhook Community Justice Center and Harlem Community Justice Center\n",
    "\n",
    "# We only retreive the cases after 03/20/2020 when NYC declared a city lockdown \n",
    "\n",
    "\n",
    "\n",
    "######################### Total filling of eviction in NYC after NYC lockdown (03/20/2020) #########################\n",
    "query = \"\"\"\n",
    "select count(*)\n",
    "from eviction_cases\n",
    "where fileddate > '2020-03-20'\n",
    "  and classification in ('Holdover','Non-Payment')\n",
    "  and court in (\n",
    "\t\t\t\t\t'Bronx County Civil Court',\n",
    "\t\t\t\t\t'Kings County Civil Court',\n",
    "\t\t\t\t\t'New York County Civil Court',\n",
    "\t\t\t\t\t'Queens County Civil Court',\n",
    "\t\t\t\t\t'Richmond County Civil Court',\n",
    "\t\t\t\t\t'Redhook Community Justice Center',\n",
    "\t\t\t\t\t'Harlem Community Justice Center'\n",
    "\t\t\t\t)\n",
    "\n",
    "\"\"\"\n",
    "total_eviction_filling_after_lockdown = spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "julian-correlation",
   "metadata": {},
   "source": [
    "## Per case filed date and disposed date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "fantastic-pottery",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+----------+-------------+\n",
      "| fileddate|disposeddate|week_filed|week_disposed|\n",
      "+----------+------------+----------+-------------+\n",
      "|2020-03-24|        null|2020-03-23|         null|\n",
      "|2020-04-14|  2021-03-08|2020-04-13|   2021-03-08|\n",
      "|2020-04-14|        null|2020-04-13|         null|\n",
      "|2020-04-17|        null|2020-04-13|         null|\n",
      "|2020-05-12|        null|2020-05-11|         null|\n",
      "|2020-05-12|        null|2020-05-11|         null|\n",
      "|2020-05-12|        null|2020-05-11|         null|\n",
      "|2020-05-12|        null|2020-05-11|         null|\n",
      "|2020-06-15|        null|2020-06-15|         null|\n",
      "|2020-06-23|        null|2020-06-22|         null|\n",
      "|2020-06-23|        null|2020-06-22|         null|\n",
      "|2020-06-25|        null|2020-06-22|         null|\n",
      "|2020-06-25|        null|2020-06-22|         null|\n",
      "|2020-06-26|        null|2020-06-22|         null|\n",
      "|2020-06-26|        null|2020-06-22|         null|\n",
      "|2020-06-29|        null|2020-06-29|         null|\n",
      "|2020-06-30|        null|2020-06-29|         null|\n",
      "|2020-06-30|          27|2020-06-29|         null|\n",
      "|2020-06-30|        null|2020-06-29|         null|\n",
      "|2020-07-01|      Active|2020-06-29|         null|\n",
      "+----------+------------+----------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "######################### case file date and disposed date #########################\n",
    "\n",
    "# Each row represents each eviction case's fileddate, disposeddate, week_filed and week_disposed\n",
    "# This is used for later data cleanning and integration\n",
    "\n",
    "######################### case file date and disposed date #########################\n",
    "query_after_lockdown_eviction_cases = \"\"\"\n",
    "select fileddate,\n",
    "       disposeddate,\n",
    "       cast(date_trunc('week', fileddate) as date)    as week_filed,\n",
    "       cast(date_trunc('week', disposeddate) as date) as week_disposed\n",
    "from eviction_cases\n",
    "where classification in ('Holdover', 'Non-Payment')\n",
    "  and court in ('Bronx County Civil Court',\n",
    "                'Kings County Civil Court',\n",
    "                'New York County Civil Court',\n",
    "                'Queens County Civil Court',\n",
    "                'Richmond County Civil Court',\n",
    "                'Redhook Community Justice Center',\n",
    "                'Harlem Community Justice Center')\n",
    "  and fileddate > '2020-03-20'\n",
    "  --and propertytype = 'Residential' # commented out to show Statewide evictions, which includes commercial\n",
    "order by fileddate asc\n",
    "\"\"\"\n",
    "after_lockdown_eviction_cases = spark.sql(query_after_lockdown_eviction_cases)\n",
    "after_lockdown_eviction_cases.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "plain-rachel",
   "metadata": {},
   "source": [
    "## Per week case filed date and disposed date with running sum and total active cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "worst-minority",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----------+--------------+----------------------+-------------------------+------------+\n",
      "|first_day_of_week|cases_filed|cases_disposed|cumulative_cases_filed|cumulative_cases_disposed|active_cases|\n",
      "+-----------------+-----------+--------------+----------------------+-------------------------+------------+\n",
      "|       2019-12-30|       1137|           577|                  1137|                      577|         560|\n",
      "|       2020-01-06|       3789|          1808|                  4926|                     2385|        2541|\n",
      "|       2020-01-13|       3955|          1765|                  8881|                     4150|        4731|\n",
      "|       2020-01-20|       3377|          1370|                 12258|                     5520|        6738|\n",
      "|       2020-01-27|       2998|          1111|                 15256|                     6631|        8625|\n",
      "|       2020-02-03|       3866|          1313|                 19122|                     7944|       11178|\n",
      "|       2020-02-10|       3264|           926|                 22386|                     8870|       13516|\n",
      "|       2020-02-17|       3359|           802|                 25745|                     9672|       16073|\n",
      "|       2020-02-24|       3481|           565|                 29226|                    10237|       18989|\n",
      "|       2020-03-02|       3820|           245|                 33046|                    10482|       22564|\n",
      "|       2020-03-09|       3224|           134|                 36270|                    10616|       25654|\n",
      "|       2020-03-16|       2463|            57|                 38733|                    10673|       28060|\n",
      "|       2020-03-23|          1|             0|                 38734|                    10673|       28061|\n",
      "|       2020-04-13|          3|             1|                 38737|                    10674|       28063|\n",
      "|       2020-05-11|          4|             0|                 38741|                    10674|       28067|\n",
      "|       2020-06-15|          1|             0|                 38742|                    10674|       28068|\n",
      "|       2020-06-22|          6|             0|                 38748|                    10674|       28074|\n",
      "|       2020-06-29|         22|             2|                 38770|                    10676|       28094|\n",
      "|       2020-07-06|         79|             9|                 38849|                    10685|       28164|\n",
      "|       2020-07-13|        273|            34|                 39122|                    10719|       28403|\n",
      "+-----------------+-----------+--------------+----------------------+-------------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "######################### case file date and disposed date with running sum and total active cases #########################\n",
    "\n",
    "# Each row represents each week (starting from 03/20/2020), the number of cases has been filed, the number of cases has been disposed,\n",
    "# the cumulative cases for each one\n",
    "# and the total active cases (filed_cases - disposed_cases)\n",
    "\n",
    "# Will draw a time series graph using this data\n",
    "\n",
    "######################### case file date and disposed date with running sum and total active cases #########################\n",
    "query_eviction_cases_time_and_summary = \"\"\"\n",
    "with after_lockdown as (\n",
    "    select fileddate,\n",
    "           cast(date_trunc('week', fileddate) as date)    as week_filed,\n",
    "           disposeddate,\n",
    "           cast(date_trunc('week', disposeddate) as date) as week_disposed\n",
    "    from eviction_cases\n",
    "    where classification in ('Holdover', 'Non-Payment')\n",
    "      and court in ('Bronx County Civil Court',\n",
    "                    'Kings County Civil Court',\n",
    "                    'New York County Civil Court',\n",
    "                    'Queens County Civil Court',\n",
    "                    'Richmond County Civil Court',\n",
    "                    'Redhook Community Justice Center',\n",
    "                    'Harlem Community Justice Center')\n",
    "      and fileddate > '2020-01-01'\n",
    "    order by fileddate asc),\n",
    "\n",
    "     group_by_week as (\n",
    "         select week_filed                                        as first_day_of_week,\n",
    "                count(*) filter (where week_filed is not null)    as cases_filed,\n",
    "                count(*) filter (where week_disposed is not null) as cases_disposed\n",
    "         from after_lockdown\n",
    "         group by week_filed\n",
    "         order by week_filed)\n",
    "\n",
    "select first_day_of_week,\n",
    "       cases_filed,\n",
    "       cases_disposed,\n",
    "       sum(cases_filed) over (order by first_day_of_week)      as cumulative_cases_filed,\n",
    "       sum(cases_disposed) over (order by first_day_of_week)   as cumulative_cases_disposed,\n",
    "       (sum(cases_filed) over (order by first_day_of_week) -\n",
    "        sum(cases_disposed) over (order by first_day_of_week)) as active_cases\n",
    "from group_by_week\n",
    "\"\"\"\n",
    "\n",
    "eviction_cases_time_and_summary = spark.sql(query_eviction_cases_time_and_summary)\n",
    "eviction_cases_time_and_summary.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sharp-brush",
   "metadata": {},
   "source": [
    "## Covid case by week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "economic-sierra",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----------------+\n",
      "|first_day_of_week|covid_case_count|\n",
      "+-----------------+----------------+\n",
      "|       2020-02-24|               1|\n",
      "|       2020-03-02|              45|\n",
      "|       2020-03-09|            2932|\n",
      "|       2020-03-16|           20476|\n",
      "|       2020-03-23|           30148|\n",
      "|       2020-03-30|           36098|\n",
      "|       2020-04-06|           34177|\n",
      "|       2020-04-13|           22964|\n",
      "|       2020-04-20|           18276|\n",
      "|       2020-04-27|           13109|\n",
      "|       2020-05-04|            7894|\n",
      "|       2020-05-11|            6678|\n",
      "|       2020-05-18|            6004|\n",
      "|       2020-05-25|            4128|\n",
      "|       2020-06-01|            3142|\n",
      "|       2020-06-08|            2387|\n",
      "|       2020-06-15|            2272|\n",
      "|       2020-06-22|            2188|\n",
      "|       2020-06-29|            2201|\n",
      "|       2020-07-06|            2514|\n",
      "+-----------------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "select first_day_of_week, sum(CASE_COUNT) as covid_case_count\n",
    "from\n",
    "(select date_of_interest, cast(date_trunc('week', date_of_interest) as date) as first_day_of_week, CASE_COUNT\n",
    "from covid_cases)\n",
    "group by first_day_of_week\n",
    "order by first_day_of_week\n",
    "\"\"\"\n",
    "\n",
    "covid_cases_time_and_summary = spark.sql(query)\n",
    "covid_cases_time_and_summary.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "loved-supplement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- date_of_interest: timestamp (nullable = true)\n",
      " |-- CASE_COUNT: integer (nullable = true)\n",
      " |-- PROBABLE_CASE_COUNT: integer (nullable = true)\n",
      " |-- CASE_COUNT_7DAY_AVG: integer (nullable = true)\n",
      " |-- ALL_CASE_COUNT_7DAY_AVG: integer (nullable = true)\n",
      " |-- BX_CASE_COUNT: integer (nullable = true)\n",
      " |-- BX_PROBABLE_CASE_COUNT: integer (nullable = true)\n",
      " |-- BX_CASE_COUNT_7DAY_AVG: integer (nullable = true)\n",
      " |-- BX_ALL_CASE_COUNT_7DAY_AVG: integer (nullable = true)\n",
      " |-- BK_CASE_COUNT: integer (nullable = true)\n",
      " |-- BK_PROBABLE_CASE_COUNT: integer (nullable = true)\n",
      " |-- BK_CASE_COUNT_7DAY_AVG: integer (nullable = true)\n",
      " |-- BK_ALL_CASE_COUNT_7DAY_AVG: integer (nullable = true)\n",
      " |-- MN_CASE_COUNT: integer (nullable = true)\n",
      " |-- MN_PROBABLE_CASE_COUNT: integer (nullable = true)\n",
      " |-- MN_CASE_COUNT_7DAY_AVG: integer (nullable = true)\n",
      " |-- MN_ALL_CASE_COUNT_7DAY_AVG: integer (nullable = true)\n",
      " |-- QN_CASE_COUNT: integer (nullable = true)\n",
      " |-- QN_PROBABLE_CASE_COUNT: integer (nullable = true)\n",
      " |-- QN_CASE_COUNT_7DAY_AVG: integer (nullable = true)\n",
      " |-- QN_ALL_CASE_COUNT_7DAY_AVG: integer (nullable = true)\n",
      " |-- SI_CASE_COUNT: integer (nullable = true)\n",
      " |-- SI_PROBABLE_CASE_COUNT: integer (nullable = true)\n",
      " |-- SI_CASE_COUNT_7DAY_AVG: integer (nullable = true)\n",
      " |-- SI_ALL_CASE_COUNT_7DAY_AVG: integer (nullable = true)\n",
      " |-- INCOMPLETE: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "covid_cases.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "thick-contrary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(covid_cases)\n",
    "# covid_cases.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elder-usage",
   "metadata": {},
   "source": [
    "## Case by zip code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "assigned-attempt",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|zip_code|total|\n",
      "+--------+-----+\n",
      "|   10001|  253|\n",
      "|   10002|  221|\n",
      "|   10003|  162|\n",
      "|   10004|   24|\n",
      "|   10005|   58|\n",
      "|   10006|   18|\n",
      "|   10007|   14|\n",
      "|   10009|  119|\n",
      "|   10010|   52|\n",
      "|   10011|  219|\n",
      "|   10012|  104|\n",
      "|   10013|   64|\n",
      "|   10014|  150|\n",
      "|   10015|    1|\n",
      "|   10016|  206|\n",
      "|   10017|   86|\n",
      "|   10018|  140|\n",
      "|   10019|  372|\n",
      "|   10020|    1|\n",
      "|   10021|  117|\n",
      "+--------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "######################### Case by zip code  #########################\n",
    "query_eviction_cases_by_zipcode = \"\"\"\n",
    "with cases_zip as (select substr(postalcode, 1, 5) as zip_code\n",
    "                   from eviction_cases\n",
    "                            left join eviction_addresses on eviction_cases.indexnumberid = eviction_addresses.indexnumberid\n",
    "                   where classification in ('Holdover', 'Non-Payment')\n",
    "                     and court in ('Bronx County Civil Court',\n",
    "                                   'Kings County Civil Court',\n",
    "                                   'New York County Civil Court',\n",
    "                                   'Queens County Civil Court',\n",
    "                                   'Richmond County Civil Court',\n",
    "                                   'Redhook Community Justice Center',\n",
    "                                   'Harlem Community Justice Center')\n",
    "                     and fileddate > '2020-03-20'\n",
    "                     and postalcode is not null\n",
    "                     and cast(substr(postalcode, 1, 5) as int) > 1\n",
    "                     and cast(substr(postalcode, 1, 5) as int) < 20000\n",
    "                   order by fileddate asc)\n",
    "\n",
    "select zip_code,\n",
    "       count(*) as total\n",
    "from cases_zip\n",
    "group by zip_code\n",
    "order by zip_code\n",
    "\"\"\"\n",
    "\n",
    "eviction_cases_by_zipcode = spark.sql(query_eviction_cases_by_zipcode)\n",
    "eviction_cases_by_zipcode.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "severe-integer",
   "metadata": {},
   "source": [
    "## NYPD Crime Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "helpful-terrace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----------+\n",
      "|first_day_of_week|case_count|\n",
      "+-----------------+----------+\n",
      "|       2019-12-30|      4815|\n",
      "|       2020-01-06|      8513|\n",
      "|       2020-01-13|      8792|\n",
      "|       2020-01-20|      8471|\n",
      "|       2020-01-27|      8708|\n",
      "|       2020-02-03|      8738|\n",
      "|       2020-02-10|      8524|\n",
      "|       2020-02-17|      8561|\n",
      "|       2020-02-24|      8456|\n",
      "|       2020-03-02|      8647|\n",
      "|       2020-03-09|      8731|\n",
      "|       2020-03-16|      6766|\n",
      "|       2020-03-23|      5537|\n",
      "|       2020-03-30|      5491|\n",
      "|       2020-04-06|      5489|\n",
      "|       2020-04-13|      5766|\n",
      "|       2020-04-20|      6112|\n",
      "|       2020-04-27|      6702|\n",
      "|       2020-05-04|      6659|\n",
      "|       2020-05-11|      7041|\n",
      "+-----------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "select first_day_of_week, count(*) as case_count\n",
    "from\n",
    "(select CMPLNT_FR_DT, cast(date_trunc('week', CMPLNT_FR_DT) as date) as first_day_of_week, BORO_NM\n",
    "from nypd_data_2020\n",
    "union all\n",
    "select CMPLNT_FR_DT, cast(date_trunc('week', CMPLNT_FR_DT) as date) as first_day_of_week, BORO_NM\n",
    "from nypd_data_2021\n",
    ")\n",
    "where CMPLNT_FR_DT > '2020-01-01' and CMPLNT_FR_DT is not null\n",
    "group by first_day_of_week\n",
    "order by first_day_of_week asc\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "nypd_data_result = spark.sql(query)\n",
    "nypd_data_result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "returning-teacher",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------+\n",
      "|      BORO_NM|count(1)|\n",
      "+-------------+--------+\n",
      "|         null|     496|\n",
      "|       QUEENS|   87823|\n",
      "|     BROOKLYN|  116201|\n",
      "|        BRONX|   88485|\n",
      "|    MANHATTAN|   93416|\n",
      "|STATEN ISLAND|   16692|\n",
      "+-------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "select BORO_NM, count(*)\n",
    "from\n",
    "(select CMPLNT_FR_DT, BORO_NM\n",
    "from nypd_data_2020\n",
    "union all\n",
    "select CMPLNT_FR_DT, BORO_NM\n",
    "from nypd_data_2021\n",
    ")\n",
    "where CMPLNT_FR_DT > '2020-03-20' and CMPLNT_FR_DT is not null \n",
    "group by BORO_NM\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "nypd_data_result_with_BORO_NM = spark.sql(query)\n",
    "nypd_data_result_with_BORO_NM.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "checked-review",
   "metadata": {},
   "source": [
    "## Export cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "economic-soundtrack",
   "metadata": {},
   "outputs": [],
   "source": [
    "after_lockdown_eviction_cases\n",
    "eviction_cases_by_zipcode.coalesce(1).write.format('com.databricks.spark.csv').option('header', 'true').mode('overwrite').save('data/cleaned_data/eviction_cases_by_zipcode')\n",
    "eviction_cases_time_and_summary.coalesce(1).write.format('com.databricks.spark.csv').option('header', 'true').mode('overwrite').save('data/cleaned_data/eviction_cases_time_and_summary')\n",
    "covid_cases_time_and_summary.coalesce(1).write.format('com.databricks.spark.csv').option('header', 'true').mode('overwrite').save('data/cleaned_data/covid_cases_time_and_summary')\n",
    "nypd_data_result.coalesce(1).write.format('com.databricks.spark.csv').option('header', 'true').mode('overwrite').save('data/cleaned_data/nypd_data_cleaned')\n",
    "nypd_data_result_with_BORO_NM.coalesce(1).write.format('com.databricks.spark.csv').option('header', 'true').mode('overwrite').save('data/cleaned_data/nypd_datawith_BORO_NM_cleaned')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "similar-darwin",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
